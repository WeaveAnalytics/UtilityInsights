{"cells":[{"cell_type":"markdown","source":["\n","#### Run the cell below to install the required packages for Copilot\n"],"metadata":{"jupyter":{"magics_cell_name":"magics-cell-markdown","magics_signature":"27ac753c3c60167f65c4d05fa7809cd85f1f0273d5b842aca4f65a01"},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e0c94779-09b8-4450-940c-3592fbed1cbb"},{"cell_type":"code","source":["\n","#Run this cell to install the required packages for Copilot\n","%load_ext dscopilot_installer\n","%activate_dscopilot\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"magics_cell_name":"magics-cell-code","magics_signature":"6565d62221c469ab3707694ccbef2e4568d575dc1ba3ebac23f0f052","magics_version":"1.0"},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac2bda8f-d94f-443d-b130-9938a5062949"},{"cell_type":"code","source":["# Required Libraries\n","%pip install openai\n","%pip install pdf2image\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"482fa52b-2740-4156-b9d9-2f5130502389"},{"cell_type":"code","source":["# Configuration\n","GPT4V_KEY = \"REPLACE_GPT4V_KEY\"  # Your GPT4V key\n","GPT4V_ENDPOINT = \"REPLACE_GPT4V_ENDPOINT\"  # The API endpoint for your GPT4V instance"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"de030dc8-d7c8-4d24-9607-4eaa304dedcf"},{"cell_type":"code","source":["# Core Functionm to send request\n","from pdf2image import convert_from_path\n","from datetime import datetime\n","import os\n","import requests\n","import base64\n","import time\n","import shutil\n","import json\n","\n","def send_request(encoded_images):\n","    headers = {\n","        \"Content-Type\": \"application/json\",\n","        \"api-key\": GPT4V_KEY,\n","    }\n","\n","    # Payload for the request\n","    payload = {\n","        \"enhancements\": {\n","            \"ocr\": {\n","                \"enabled\": True  # enabling OCR to extract text from the image using AI vision services\n","            },\n","            \"grounding\": {\n","                \"enabled\": True  # enabling grounding to extract the context of the image using AI vision services\n","            },\n","        },\n","        \"messages\": [\n","            {\n","                \"role\": \"system\",\n","                \"content\": [\n","                    {\n","                        \"type\": \"text\",\n","                        \"text\": \"\"\"\n","                            You are a field extraction expert. When given a series of images, extract all the fields into a JSON object structure.\n","                            Treat the series of documents as one cohesive document and return a json mapping all the appropriate fields.\n","                            Rewrite json key actual_reading column beginning with the higher month to be called actual_reading_end_reading.\n","                            Rewrite json key actual_reading column start with the lower month to be called acual_reading_begin_reading\n","                            Convert all dates to MM-DD-YYY format.\n","                            Process fields that don't have values as null.\n","                            Only output the following items in JSON Object.\n","                            Output json exactly like this:\n","                  {\n","    \"company\": \"PSE&G\",\n","    \"total_amount_due\": \"631.78\",\n","    \"due_date\": \"1/1/2021\",\n","    \"bill_date\": \"1/31/2021\",\n","    \"billing_period_start\": \"01/31/2024\",\n","    \"billing_period_end\": \"1/31/2024\",\n","    \"account_number\": \"REDACTED\",\n","    \"service_address\": \"REDACTED\",\n","    \"balance_remaining_from_last_bill\": \"128.28\",\n","    \"this_month_charges_and_credits\": \"103.50\",\n","    \"payment_received\": \"0.00\",\n","    \"balance_remaining\": \"128.28\",\n","    \"electric_usage\": \"6.0% less compared to this month last year\",\n","    \"electric_charges\": \"234.85\",\n","    \"electric_actual_reading_begin\": \"1111\",\n","    \"electric_actual_reading_end\": \"222\",\n","    \"electric_usage_difference\": \"189\",\n","    \"electric_service_charge\": \"1.95\",\n","    \"electric_delivery_charges\": \"2.96\",\n","    \"electric_supply_charges\": \"2.89\",\n","    \"electric_total_charges\": \"100.85\",\n","    \"gas_usage\": \"4.6% less compared to this month last year\",\n","    \"gas_actual_begin_reading\": \"2761\",\n","    \"gas_actual_end_reading\": \"2914\",\n","    \"gas_difference\": \"153\",\n","    \"gas_converted_to_ccf\": \"154.836\",\n","    \"gas_total_used_therms\": \"160.255\",\n","    \"gas_monthly_service_charge\": \"8.62\",\n","    \"gas_delivery_charges\": \"104.95\",\n","    \"gas_supply_charges\": \"63.70\",\n","    \"gas_total_charges\": \"168.65\"\n","}\n","                        \"\"\"\n","                    }\n","                ]\n","            },\n","            {\n","                \"role\": \"user\",\n","                \"content\": [\n","                    {\n","                        \"type\": \"text\",\n","                        \"text\": \"Return the fields in this document as a complete json object\",\n","                    },\n","                ],\n","            },\n","        ],\n","        \"temperature\": 0,\n","        \"top_p\": 0,\n","        \"max_tokens\": 4096,\n","    }\n","\n","    # Add an item for each encoded image, limited to 10 images\n","    for encoded_image in encoded_images[:10]:\n","        payload[\"messages\"][1][\"content\"].append({\n","            \"type\": \"image_url\",\n","            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{encoded_image}\"},\n","        })\n","\n","    # Send request\n","    try:\n","        response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n","        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n","        json_response = response.json()\n","    except requests.RequestException as e:\n","        raise SystemExit(f\"Failed to make the request. Error: {e}\")\n","    return json_response"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3f17ac56-be88-4b81-9c18-c593f608372e"},{"cell_type":"code","source":["# Main Functions\n","\n","def convert_pdf_to_images(pdf_file_path, image_path):\n","    # Convert PDF file to images\n","    images = convert_from_path(pdf_file_path)\n","    # Save images in new folder\n","    new_image_folder_path = os.path.join(image_path, f'{os.path.splitext(os.path.basename(pdf_file_path))[0]}_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}')\n","    os.makedirs(new_image_folder_path)\n","    for i, image in enumerate(images):\n","        image.save(os.path.join(new_image_folder_path, f\"page{(i+1):02}.jpg\"), \"JPEG\")\n","    return new_image_folder_path\n","\n","def encode_images(image_folder_path):\n","    encoded_images = []\n","    image_file_paths = [os.path.join(image_folder_path, file) for file in os.listdir(image_folder_path)]\n","    for image_file_path in image_file_paths:\n","        encoded_image = base64.b64encode(open(image_file_path, \"rb\").read()).decode(\"ascii\")\n","        encoded_images.append(encoded_image)\n","    return encoded_images\n","\n","def clean_json_response(response_content):\n","    # Clean up the response's content. Convert the response's json string to a json object\n","    # Remove the leading and trailing characters\n","    json_string = response_content.replace('```json\\n', '')\n","    json_string = json_string.rsplit('\\n', 1)[0]\n","    try:\n","        # Try to parse the JSON string into a Python dictionary\n","        json_object = json.loads(json_string)\n","        print(json_string)\n","    except json.JSONDecodeError:\n","        print(\"The JSON string is not complete.\")\n","    return json_object\n","\n","def write_json_to_file(pdf_file, json_path, json_object):\n","    # Create the 'JSON Output' folder \n","    new_json_folder_path = os.path.join(json_path, f'{os.path.splitext(pdf_file)[0]}_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}')\n","    os.makedirs(new_json_folder_path)\n","    # Write the response to a JSON file in the 'JSON Output' folder\n","    json_output_filename = os.path.splitext(pdf_file)[0] + \".json\"\n","    json_output_filepath = os.path.join(new_json_folder_path, json_output_filename)\n","    with open(json_output_filepath, \"w\") as file:\n","        json.dump(json_object, file, indent=4)\n","    return json_output_filepath\n","\n","def archive_pdf_to_folder(pdf_file, pdf_file_path, archive_folder_path):\n","    # Create new 'Archive' folder\n","    new_archive_folder_path = os.path.join(archive_folder_path,f'{os.path.splitext(pdf_file)[0]}_{datetime.now().strftime(\"%Y%m%d%H%M%S\")}')\n","    os.makedirs(new_archive_folder_path)\n","   # Move all files from source to destination\n","    shutil.move(pdf_file_path, new_archive_folder_path)\n","\n","def load_json_to_table(processsed_json):\n","    new_path = processsed_json.replace(\"/lakehouse/default/\", \"\")\n","    df = spark.read.option(\"multiLine\", \"true\").json(new_path)\n","    df.write.mode(\"append\").saveAsTable(\"bills\")\n","\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4ded64bd-9c65-41a1-a563-fa6a058d72d0"},{"cell_type":"code","source":["# Runner\n","lakehouse_path = \"/lakehouse/default/Files\"\n","pdf_folder_path = f\"{lakehouse_path}/invoices/\" # Path to pdf folder\n","json_folder_path = f\"{lakehouse_path}/json/\" # Path to json output folder\n","image_folder_path = f\"{lakehouse_path}/images/\" # Path to images\n","archive_folder_path = f\"{lakehouse_path}/processed/\" # Path to archive folder\n","def runner():\n","    # Get a list of all paths of the pdfs in the pdf folder\n","    #pdf_paths = [os.path.join(pdf_folder_path, file) for file in os.listdir(pdf_folder_path)]\n","    # Run the extractor for every pdf in the folder\n","    for pdf_file in os.listdir(pdf_folder_path):\n","        # Convert PDF's to Images\n","        pdf_file_path = os.path.join(pdf_folder_path, pdf_file)\n","        new_image_folder_path = convert_pdf_to_images(pdf_file_path, image_folder_path)\n","        # Encode all images in new image folder\n","        encoded_images = encode_images(new_image_folder_path)\n","        # Send Request to GPT4V to Return JSON structure from Images\n","        json_response = send_request(encoded_images)\n","        # Get the content from the response\n","        response_content = json_response[\"choices\"][0][\"message\"][\"content\"]\n","        # Clean the response\n","        json_object = clean_json_response(response_content)\n","        # Add file name to JSON \n","        json_object['file_name'] = pdf_file\n","        # Output to Output folder directory\n","        processsed_json = write_json_to_file(pdf_file, json_folder_path, json_object)\n","        # Load JSON files to table\n","        load_json_to_table(processsed_json)\n","        # Move processed pdf to archive folder\n","        archive_pdf_to_folder(pdf_file, pdf_file_path, archive_folder_path)\n","\n","# Run Extractor\n","new_json_folder_paths = runner()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fbdbb939-b50e-4530-9702-237608c0ba3e"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"default_lakehouse":"402f36e8-aea0-4725-8dfa-a8b0f3ea59a4","default_lakehouse_name":"BillExtraction","default_lakehouse_workspace_id":"dbee09d1-0883-4c24-81cd-f870f2d3e4e5"},"environment":{}}},"nbformat":4,"nbformat_minor":5}